---
title: "<strong>Advanced `R`</strong>"
author: "andrés castro araújo"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output: 
  html_document: 
    theme: paper
    toc: yes
    toc_float:
      collapsed: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", fig.align = "center")

# library(tidyverse)
# theme_set(theme_minimal(base_family = "Avenir", base_line_size = 0))

library(magrittr)
```

```{css, echo=FALSE}
blockquote {
    padding: 10px 20px;
    margin: 0 0 20px;
    font-size: 14px;
    color: #828282;
    border-left: 10px solid #EEE;
}

body {
    font-size: 14px;
}
```

>All of this is taken from Hadley Wickham's [__Advanced R__](https://adv-r.hadley.nz). CRC Press, 2019.

****

## Introduction

Some things about `R` are different from what you'd expect to see in other programming languages. Here's a non-exhaustive list:

1. Copy-on-modify semantics, which refer to the allocation of memory makes sense once we really understand the difference between an object and its name.

2. In `R`, _almost_ everything is a vector. And almost everything that happens is a _function call_.

3. There are three subsetting operators, `[[`, `[`, and `$`, and all of them interact in different ways with different vector types.

4. R has aspects of both functional and object-oriented (OO) programming languages. These things are covered in two separate notebooks, but the foundations for both of them are contained here.

In this section, we cover copy-on-modify semantics, vectors and subsetting.

### Copy-on-modify semantics

We’ll use the `lobstr` package to dig into the internal representation of R objects.

```{r}
library(lobstr)
```

Suppose we want to contain an object `x` that contains the values 1, 2, and 3.

```{r}
x <- c(1, 2, 3)
```

But this is _not_ an object with a name. R first creates a vector of values `c(1,2,3)` and then binds that object to a name `x`. 

>In other words, the object, or value, doesn’t have a name; it’s actually the name that has a value.

Thus, names are actually references to values. And if we now run `y <- x`, we don't get another copy of the value `c(1,2,3)`; instead, we get another binding to the existing object.

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/bdc72c04d3135f19fb3ab13731129eb84c9170af/f0ab9/diagrams/name-value/binding-2.png"
)
```

The `0x74b` refers to the object independently of its bindings. We can use `lobstr` to see that both `x` and `y` point to the same identifier. Note that these identifiers are long, and change every time you restart R.

```{r}
obj_addr(x)
y <- x
obj_addr(y)
```

Now suppose we modify `y`, but not `x`. 

```{r}
y[[2]] <- 100
```

R creates a new object `0xcd2`, which is basically the same as `0x74b` with one value change. Finally, the name `y` is rebound to that new object.

```{r, echo=FALSE, out.width="170px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/ef9f480effa2f1d0e401d1f94218d0cf118433c0/b56e9/diagrams/name-value/binding-3.png"
)
```

>This behaviour is called __copy-on-modify.__ Understanding it will radically improve your intuition about the performance of R code.

This, for example, explains why loops perform better when we feed them a vector of adequate size.

```{r}
output <- vector("integer", length = 3)
for (i in 1:5) {
  output[[i]] <- i
  print(obj_addr(output)) ## remains the same while vector is length = 3
}
```

__Lists__

The elements of a list point to values, they behave just like names. Instead of storing the values themselves, 

```{r}
l1 <- l2 <- list(1, 2, 3)
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/52bc0e3da3382cba957a9d83397b6c9200906ce2/c72aa/diagrams/name-value/l-modify-1.png"
)
```

```{r}
l2[[3]] <- 4
```

```{r, echo=FALSE, out.width="180px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/b844bb5a3443e1344299627f5760e2ae3a9885b5/e1c76/diagrams/name-value/l-modify-2.png"
)
```

>Like vectors, lists use copy-on-modify behaviour; the original list is left unchanged, and R creates a modified copy. This, however, is a __shallow copy__: the list object and its bindings are copied, but the values pointed to by the bindings are not.

We can use `lobstr::ref()` to see the values that are shared across both lists.

```{r}
lobstr::ref(l1, l2)
```

And because values are being shared, the size of lists is sometimes unintuitive. More generally, `obj_size(x)` + `obj_size(y)` will only equal `obj_size(x, y)`
if they share no values.

```{r}
x <- runif(1000)
y <- list(x, x, x)
ref(x, y)
obj_size(x) + obj_size(y)
obj_size(x, y)
```

__Data frames__

Data frames are lists of vectors, so copy-on-modify works very similar in this setting, except the following:

- "If you modify a column, only that column needs to be modified; the others will still point to their original references."

- "However, if you modify a row, every column is modified, which means every column must be copied."

****

>Note. The latests versions of R have a feature called ALTREP, short for __alternative representation__. It allows for R to represent some types of vectors very compactly. The place you are most likely to see this is with `:` because instead of storing every single number in the sequence, R just stores the first and last number.

```{r}
obj_size(c(1, 2, 3, 4, 5))
obj_size(1:5)
x <- 1:5000
obj_size(x)
x[[333]] <- 9 ## note the massive increase in size
obj_size(x) 
```

****

An important exception with regards to the copy-on-modify semantics occurs with `environments`, a special type of object that is always __modified on place__.

>This property is sometimes described as __reference semantics__ because when you modify an environment all existing bindings to that environment continue to have the same reference.

### Vectors

There are two types of vectors in R:

- __Atomic vectors__, of which there are six types: `logical`, `integer`, `double`, `character`, `complex`, and `raw.` Integer and double vectors are collectively known as _numeric_ vectors.

    You can determine the type of a vector with the `typeof()` function.

- __Lists__, which are sometimes called recursive vectors (because lists can contain other lists). Other times they're called generic vectors to emphasise their difference from atomic vectors.

The chief difference between atomic vectors and lists is that atomic vectors are _homogeneous_, while lists can be _heterogeneous._ There’s one other related object: `NULL`, which is often used to represent the absence of a vector (as opposed to `NA`, which is used to represent the absence of a value in a vector).

Most computations involving a missing value will return another missing value, with a couple of obvious exceptions:

```{r}
NA^0
NA | TRUE
NA & FALSE
```

___Attributes___

Every vector can have __attributes__ (i.e. a named list of arbitrary metadata). Two attributes are particularly important: _dimension_, which turns vectors into matrices and arrays; and _class_, which powers the S3 object system.

You can _name_ a vector in three ways:

```{r}
# When creating it: 
x <- c(a = 1, b = 2, c = 3)

# By assigning a character vector to names()
x <- 1:3
names(x) <- c("a", "b", "c")

# Inline, with setNames():
x <- setNames(1:3, c("a", "b", "c"))
```

```{r}
str(x)
```

Other attributes are set (or retrieved) with the `attr()` function,

```{r}
attr(x, "names") <- c("a", "b", "c")
attr(x, "arbitrary") <- rnorm(1)
str(x)
```

And we can extract all of them with the `attributes()` function.

```{r}
attr(x, "arbitrary")
attributes(x) ## returns a named list
```

__Dimensions__

Adding a `dim` attribute to a vector allows it to behave like a 2-dimensional matrix or a multi-dimensional array.

```{r}
x <- 1:20
dim(x) <- c(4, 5)
x
dim(x) <- c(2, 5, 2)
x
```

Note that many of the functions for working with vectors have generalisations for matrices and arrays:

```{r, echo=FALSE}
knitr::kable(
tibble::tibble(
  vector = c("`names()`", "`length()`", "`c()`", "", "`is.null(dim(x))`"),
  matrix = c("`rownames()`, `colnames()`", "`nrow()`, `ncol()`", "`rbind()`, `cbind()`", "`t()`", "`is.matrix()`"),
  array = c("`dimnames()`", "`dim()`", "`abind::abind()`", "`aperm()`", "`is.array()`"))
) %>% 
  kableExtra::kable_styling(full_width = FALSE, bootstrap_options = "bordered")
```

___S3 atomic vectors___

Having a __`class`__ attribute turns an object into an _S3 object_, which makes it behave differently from a regular vector when passed to a _generic function_.

Four types of important S3 vectors used in R:

- `factor` vectors, used to store categorical data. where values come Factors are built on top of an integer vector with two attributes: a "factor" `class`, which makes them behave differently from regular integer vectors; and "levels", which defines the set of allowed values.

    "Ordered factors" are a minor variation of factors (i.e. a < b < c).

- Dates (with day resolution), which are recorded in `Date` vectors. They're built on top of "double" vectors. They have a class “Date”, and no other attributes.

    The value of the double, represents the number of days since "1970-01-01" (also known as the Unix Epoch).
    
    ```{r}
    x <- 0
    class(x) <- "Date"
    x
    ```

- Date-times are much like dates, except that they also have second or sub-second resolution. These are also built on top of doubles, but they have a `POSIXct` class.

    >"POSIX" is short for Portable Operating System Interface, which is a family of cross-platform standards. "ct" standards for calendar time (the `time_t` type in C).

    ```{r}
    x <- as.POSIXct("1990-03-04 2:00", tz = "UTC")
    x
    attributes(x)
    attr(x, which = "tzone") <- "EST"
    x
    ```

    >The `tzone` attribute controls only how the date-time is formatted; it does not control the instant of time represented by the vector.
    
    EST stands for Eastern Daylight Time, whereas UTC stands for [Universal Time Coordinated](https://en.wikipedia.org/wiki/Coordinated_Universal_Time).

- Durations, which are stored in `difftime` vectors. They're built on top of doubles and have an additional units attribute that determines how to interpret the numeric value.

    ```{r}
    x - x
    class(x - x)
    as.difftime(1.5, units = "weeks")
    ```

___Lists___

Every element of a list can be of any type. Technically speaking, however, each element of list is really a reference (or a binding) to another object, which can be of any type.

>This makes them fundamentally different from atomic vectors.

You can turn a list into an atomic vector with `unlist()`. But the rules for the resulting type are complex and not well documented.

The most important S3 vectors that are built upon lists are data frames and tibbles. In both cases, the length of each of its vectors must be the same. 

```{r}
typeof(mtcars)
attributes(mtcars)
```

Tibbles, on the other hand, are provided by the [__`tibble`__](https://tibble.tidyverse.org/) package.

>A concise, and fun, way to summarise the main differences is that tibbles are lazy [they don't coerce their input (e.g. `stringsAsFactors = FALSE`)] and surly: they do less and complain more.

```{r}
library(tibble)
df <- tibble(x = 1:3, y = LETTERS[1:3])
typeof(df)
attributes(df)
```

But perhaps the biggest difference between data frames and tibbles is that the later are designed to disregard rownames.

```{r}
attributes(as_tibble(mtcars))
```

>There are three reasons why row names are undesirable:
>
>1. Metadata is data, so storing it in a different way to the rest of the data is fundamentally a bad idea. It also means that you need to learn a new set of tools to work with row names; you can’t use what you already know about manipulating columns.
>
>2. Row names are a poor abstraction for labelling rows because they only work when a row can be identified by a single string. This fails in many cases, for example when you want to identify a row by a non-character vector (e.g. a time point), or with multiple vectors (e.g. position, encoded by latitude and longitude).
>
>3. Row names must be unique, so any duplication of rows (e.g. from bootstrapping) will create new row names. If you want to match rows from before and after the transformation, you’ll need to perform complicated string surgery.
>
>For these reasons, tibbles do not support row names. Instead the tibble package provides tools to easily convert row names into a regular column with either `rownames_to_column()`, or the `rownames` argument in `as_tibble()`.

Finally, making use of _list-columns_ with tibbles is much easier.

>Since a data frame is a list of vectors, it is possible for a data frame to have a column that is a list. This is very useful because a list can contain any other object: this means you can put any object in a data frame. This allows you to keep related objects together in a row, no matter how complex the individual objects are.

```{r, error=TRUE}
df <- data.frame(x = 1:3)
df$y <- list(1:2, 1:3, 1:4)
df

data.frame(
  x = 1:3, 
  y = list(1:2, 1:3, 1:4)  ## This doesn't work!
)

tibble(
  x = 1:3, 
  y = list(1:2, 1:3, 1:4)
)

```

### Subsetting

>Subsetting is a natural complement to `str()`. While `str()` shows you all the pieces of any object (its structure), subsetting allows you to pull out the pieces that you’re interested in. 

R has three subsetting operators: `[`, `[[`, and `$`. The `[` operator lets you subset atomic vectors.

___Six ways to subset atomic vectors.___

```{r, error=TRUE}
## 1. Positive integers
letters[3:1]
letters[c(2, 2, 2)]
letters[c(1.9, 2.1, 2.8)] ## silently truncated to integers

## 2. Negative integers
letters[1:20 * -1]
letters[c(-1, 2)] ## can't mix!

## 3. Logical vectors
letters > "m"
letters[letters > "m"]

## 4. Nothing. Useful for matrices, data frames, and arrays
letters[]

## 5. Zero returns a zero-length vector. Usually not done on purpose
letters[0]
```

Finally, if the vector is _named_, you can use character vectors to return elements with matching names.

```{r}
## 6. Character vectors
(y <- setNames(1:4, letters[1:4]))
y["c"]
y[c("a", "a", "c", "a", "x")]
```

A final word of caution:

>Factors are not treated specially when subsetting. This means that subsetting will use the underlying integer vector, not the character levels. This is typically unexpected, so you should avoid subsetting with factors.

___Subsetting operators interact differently with different vector types (e.g., atomic vectors, lists, factors, matrices, and data frames)___

- Subsetting a list will work in the same way as subsetting atomic vectors. `[` always returns a list, whereas `[[` and `$` pull elements out of a list.

- The easiest way of subsetting matrices (2D) and arrays (>2D) is to supply a 1D index for each dimension separated by a comma.

    And because both matrices and arrays are just vectors with special a `dimension` attribute, you can always subset them with a single vector (i.e. treat them as if they were a 1D vector). 
    
    Note: Arrays in R are stored in column-major order.
    
- We can also subset matrices and arrays with a matrix (integer, logical, and character if named).

    For example:

    ```{r}
    x <- outer(1:4, 1:4, FUN = "+")
    x
    upper.tri(x)
    x[upper.tri(x)]
    ```

- Subsetting a data frame with a simple index makes it behave like a list (e.g. `df[1:2]` selects the first two columns).

    Subsetting a data frame with two indices makes it behave like a matrix (e.g. `df[1:3, ]` selects the first three rows).

    >By default, subsetting a matrix or data frame with a single number, a single name, or a logical vector containing a single `TRUE`, will simplify the returned output, i.e. it will return an object with lower dimensionality. To preserve the original dimensionality, you must use `drop = FALSE`.

    Tibbles have `drop = FALSE` by default.

>_Exercise. Implement your own function that extracts the diagonal entries from a matrix (it should behave like diag(x) where x is a matrix)._

```{r}
extract_diag <- function(x) {      # When subsetting with integer matrices,
  end <- min(nrow(x), ncol(x))     # each row specifies the location of one 
  return(x[cbind(1:end, 1:end)])   # value, and each column corresponds to a 
}                                  # dimension in the array.
```

___Selecting a single element___

The `[[` operator is used for extracting single items; `$`, on the other hand, is a shorthand operator: `x$y` is equivalent to `x[["y"]]`. These operators are mostly useful when working with lists, because while `[` returns a smaller list, `[[` will actually extract the content of that list.

```{r}
mtcars[["mpg"]]
identical(mtcars[["mpg"]], mtcars$mpg)
```

>Because `[[` can return only a single item, you must use it with either a single positive integer or a single string. If you use a vector with `[[`, it will subset recursively, i.e. `x[[c(1, 2)]]` is equivalent to `x[[1]][[2]]`. This is a quirky feature that few know about, so I recommend avoiding it in favour of `purrr::pluck()`.
>
>When the element is missing, `pluck()` always returns `NULL` (or the value of the .default argument) and `chuck()` always throws an error. The behaviour of `pluck()` makes it well suited for indexing into deeply nested data structures where the component you want may not exist (as is common when working with JSON data from web APIs). `pluck()` also allows you to mix integer and character indices, and provides an alternative default value if an item does not exist:

```{r, error=TRUE}
x <- list(
  a = list(1, 2, 3),
  b = list(3, 4, 5)
)

purrr::pluck(x, "a", 1)
purrr::pluck(x, "c", 1)
purrr::chuck(x, "c", 1)
purrr::pluck(x, "c", 1, .default = NA)
```

`$` is most commonly used to access variables in a data frame.

>One common mistake with `$` is to use it when you have the name of a column stored in a variable.

```{r}
var <- "mpg"
# Doesn't work - mtcars$var translated to mtcars[["var"]]
mtcars$var

# Instead use [[
mtcars[[var]]
```

Finally, `$` does left-to-right partial matching on regular data frames, which can be a frustrating source of errors. Tibbles, on the other hand, will never do partial matching.

___Subsetting and assignment___

>All subsetting operators can be combined with assignment to modify selected values of an input vector: this is called subassignment. The basic form is `x[i] <- value`. I recommend that you should make sure that length(value) is the same as length(x[i]), and that i is unique.

```{r}
x <- 1:5
x[c(1, 2)] <- c(101, 102)
x
```

You can use `x[[i]] <- NULL` to delete an element of a list; or use `x[[i]] <- list(NULL)` to replace an element with a literal `NULL` value.

## Subsetting applications

### Lookup tables (character subsetting)

```{r}
x <- c("m", "f", "u", "f", "f", "m", "m")
lookup <- c(m = "Male", f = "Female")
lookup[x]
unname(lookup[x]) ## if you don’t want names in the result
```

### Matching and merging by hand (integer subsetting)

>You can also have more complicated lookup tables with multiple columns of information. For example, suppose we have a vector of integer grades, and a table that describes their properties:

```{r}
grades <- c(1, 2, 2, 3, 1)

info <- tibble::tibble(
  grade = 3:1,
  desc = c("Excellent", "Good", "Poor"),
  fail = c(FALSE, FALSE, TRUE)
)

```

>Then, let’s say we want to duplicate the info table so that we have a row for each value in grades. An elegant way to do this is by combining `match()` and integer subsetting (`match(needles, haystack)` returns the position where each `needle` is found in the `haystack`).

```{r}
id <- match(grades, info$grade) 
id
info[id, ] 
```

>Note that `match()` returns a vector of the positions of (first) matches of its first argument in its second.

### Random samples and bootstraps (integer subsetting)

>You can use integer indices to randomly sample or bootstrap a vector or data frame. Just use sample(n) to generate a random permutation of 1:n, and then use the results to subset the values:

```{r}
df <- head(mtcars, n = 5) %>% tibble::as_tibble(rownames = "id")
df[sample(nrow(df), 100, replace = TRUE), ]
```

### Ordering (integer subsetting)

>`order()` takes a vector as its input and returns an integer vector describing how to order the subsetted vector. 

```{r}
x <- c("b", "c", "a")
order(x)
x[order(x)]
```

>To break ties, you can supply additional variables to `order()`. You can also change the order from ascending to descending by using `decreasing = TRUE`. By default, any missing values will be put at the end of the vector; however, you can remove them with `na.last = NA` or put them at the front with `na.last = FALSE`.

```{r}
df2 <- df[sample(nrow(df)), sample(ncol(df))] ## randomly reorder df
df2[order(df2[[1]]), ]                        ## reorder rows according to first column
df2[ , order(names(df2))]                     ## reorder rows according to first column
```

>You can sort vectors directly with `sort()`, or similarly `dplyr::arrange()`, to sort a data frame.

### Expanding aggregated counts (integer subsetting)

>Sometimes you get a data frame where identical rows have been collapsed into one and a count column has been added. `rep()` and integer subsetting make it easy to uncollapse, because we can take advantage of vectorisation: `rep(x, y)` repeats `x[i] y[i]` times.

```{r}
df <- tibble::tibble(x = c(2, 4, 1), y = c(9, 11, 6), n = c(3, 5, 1))
str(df)
rep(1:nrow(df), df$n)
df[rep(1:nrow(df), df$n), ]
```

### Removing columns from data frames (character)

>There are two ways to remove columns from a data frame. You can set individual columns to `NULL`:

```{r}
df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
df$z <- NULL
```

>Or you can subset to return only the columns you want:

```{r}
df <- tibble::tibble(x = 1:3, y = 3:1, z = letters[1:3])
df[c("x", "y")]

## use set operations when you only know the columns you don’t want
df[setdiff(names(df), "x")]
```

### Selecting rows based on a condition (logical subsetting)

>Because logical subsetting allows you to easily combine conditions from multiple columns, it’s probably the most commonly used technique for extracting rows out of a data frame.

```{r}
mtcars[mtcars$gear == 5, ]
mtcars[mtcars$gear == 5 & mtcars$cyl == 4, ]
```

<blockquote>
Remember to use the vector boolean operators `&` and `|`, not the short-circuiting scalar operators `&&` and `||`, which are more useful inside if statements. And don’t forget De Morgan’s laws, which can be useful to simplify negations:

- `!(X & Y)` is the same as `!X | !Y`

- `!(X | Y)` is the same as `!X & !Y`
</blockquote>

### `which()`

___Boolean algebra versus sets (logical and integer)___

<blockquote>
It’s useful to be aware of the natural equivalence between set operations (integer subsetting) and Boolean algebra (logical subsetting). Using set operations is more effective when:

You want to find the first (or last) `TRUE`.

You have very few `TRUE`s and very many `FALSE`s; a set representation may be faster and require less storage.

`which()` allows you to convert a Boolean representation to an integer representation.
</blockquote>

```{r}
x <- sample(8) < 4
x
which(x)
```

>There’s no reverse operation in base R but we can easily create one:

```{r}
unwhich <- function(x, n) {
  out <- rep_len(FALSE, length.out = n)
  out[x] <- TRUE
  return(out)
}
unwhich(which(x), 8)
```

<blockquote>
When first learning subsetting, a common mistake is to use `x[which(y)]` instead of `x[y]`. Here the `which()` achieves nothing: it switches from logical to integer subsetting but the result is exactly the same. In more general cases, there are two important differences.

- When the logical vector contains `NA`, logical subsetting replaces these values with `NA` while `which()` simply drops these values. It’s not uncommon to use `which()` for this side-effect, but I don’t recommend it: nothing about the name "which" implies the removal of missing values.

- `x[-which(y)]` is __not__ equivalent to `x[!y]`: if `y` is all `FALSE`, `which(y)` will be `integer(0)` and `-integer(0)` is still `integer(0)`, so you’ll get no values, instead of all values.

In general, avoid switching from logical to integer subsetting unless you want, for example, the first or last `TRUE` value.
</blockquote>

>Exercise. _How would you randomly permute the columns of a data frame? (This is an important technique in random forests.) Can you simultaneously permute the rows and columns in one step?_

```{r}
df <- head(mtcars, 10)
df[sample(nrow(df)), sample(ncol(df))]
```

## Control Flow

>__Choices__, like `if` statements and `switch()` calls, allow you to run different code depending on the input. 

>__Loops__, like `for` and `while`, allow you to repeatedly run code, typically with changing options.

### Choices

```{r, eval=FALSE}
# The basic form of an "if" statement in R
if (condition) true_action
if (condition) true_action else false_action
```

`if` statements also return values, which in turn can be used for assignments.

```{r}
x <- if (TRUE) 1; x
x <- if (FALSE) 1; x ## invisibly returns a NULL
x <- if (FALSE) 1 else 2; x
```

>The `condition` should evaluate to a single `TRUE` or `FALSE`. Most other inputs will generate an error:

```{r, error=TRUE}
if ("x") 1
if (logical()) 1
if (NA) 1
```

>The exception is a logical vector of length greater than 1, which generates a warning:

```{r}
if (c(TRUE, FALSE)) 1
```

>In R 3.5.0 and greater, thanks to [Henrik Bengtsson](https://github.com/HenrikBengtsson/Wishlist-for-R/issues/38), you can turn this into an error by setting an environment variable:

```{r, error=TRUE}
Sys.setenv("_R_CHECK_LENGTH_1_CONDITION_" = "true")
if (c(TRUE, FALSE)) 1
```

>Handling vectors of logical values is the job of `ifelse()`: a vectorised function with `test`, `yes`, and `no` vectors (that will be recycled to the same length).

```{r}
x <- 1:10
ifelse(x %% 5 == 0, "XXX", as.character(x))
ifelse(x %% 2 == 0, "even", "odd")
```

>Another vectorised equivalent is the more general `dplyr::case_when()`. It uses a special syntax to allow any number of condition-vector pairs:

```{r}
dplyr::case_when(
  x %% 3 == 0 & x %% 5 == 0 ~ "fizz buzz", 
  x %% 3 == 0 ~ "fizz",
  x %% 5 == 0 ~ "buzz",
  is.na(x) ~ "[?]",
  TRUE ~ as.character(x)
)
```

>Closely related to `if` is the `switch()` statement. It’s a compact, special purpose equivalent that lets you replace code like:

```{r}
x_option <- function(x) {
  if (x == "a") {
    "option 1"
  } else if (x == "b") {
    "option 2" 
  } else if (x == "c") {
    "option 3"
  } else {
    stop("Invalid `x` value")
  }
}
```

>with the more succint:

```{r}
x_option <- function(x) {
  switch(x,
    "a" = "option 1",
    "b" = "option 2",
    "c" = "option 3",
    stop("Invalid `x` value")
  )
}
```

>The last component of a `switch()` should always throw an error, otherwise unmatched inputs will invisibly return `NULL`.

### Loops

```{r, eval=FALSE}
# The basic form of a "loop" in R
for (item in vector) perform_action
```

>Note. `for` assigns the item to the current environment, overwriting any existing variable with the same name.

_Two ways to terminate a loop early:_

1. `next` exits the current iteration.

2. `break` exits the entire loop.

```{r}
for (i in 1:10) {
  if (i < 3) next

  print(i)
  
  if (i >= 5) break
}
```

_Three common pitfalls of `for` loops_

1. If you’re generating data, make sure to preallocate the output container. Otherwise the loop will be very slow (see copy-on-modify semantics).

    ```{r}
    x <- 1:10
    out <- vector("list", length(x))
    for (i in 1:length(out)) out[[i]] <- rnorm(10, x[[i]])
    ```

2. Beware of iterating over `1:length(x)`, which will fail in unhelpful ways if `x` has length 0.

    ```{r, error=TRUE}
    x <- numeric()
    out <- vector("list", length(x))
    for (i in 1:length(out)) out[[i]] <- rnorm(10, x[[i]])
    ```

3. Loops typically strip the attributes of S3 vectors.

```{r}
xs <- as.Date(c("2020-01-01", "2010-01-01"))
for (k in xs) print(k)  ## no longer a date
for (k in seq_along(xs)) print(xs[[k]])
```

We use `while` and `repeat` when we need to use loops, but we don't know in advance the set of values that we want to iterate over.

>You can rewrite any `for` loop to use `while` instead, and you can rewrite any `while` loop to use `repeat`, but the converses are not true. That means `while` is more flexible than `for`, and `repeat` is more flexible than `while.` It’s good practice, however, to use the least-flexible solution to a problem, so you should use `for` wherever possible.

- `while(condition) action`: performs `action` while `condition` is `TRUE`.

- `repeat(action)`: repeats `action` forever (i.e. until it encounters `break`).

    Note that R doesn't have the common `do {action} while (condition)` syntax found in other languages.

>Generally speaking you shouldn’t need to use for loops for data analysis tasks, as `map()` and `apply()` already provide less flexible solutions to most problems.

## Functions

### Fundamentals

Two important ideas:

>Functions are objects, just as vectors are objects.

>Functions can be broken down into three components: arguments, body, and environment.
>
>There are exceptions to every rule, and in this case, there is a small selection of "primitive" base functions that are implemented purely in C.

The three parts of any function can be accessed with `formals()`, `body()`, and `environment()`.

```{r}
add <- function(x, y) {
  x + y ## this comment is self explanatory
}

formals(add)
body(add)
environment(add)
```

>Like all objects in R, functions can also possess any number of additional `attributes()`. One attribute used by base R is `srcref`, short for source reference. It points to the source code used to create the function. The `srcref` is used for printing because, unlike `body()`, it contains code comments and other formatting.

```{r}
attributes(add)
```

So-called _primitive functions_, which directly call C code, don't necessarily have three components.

```{r}
## For example
is.primitive(sum)
sum

formals(sum)
body(sum)             
environment(sum)
```

These functions have either type `builtin` or type `special`.

```{r}
typeof(sum)
typeof(`[`)
```

>Primitive functions are only found in the base package. While they have certain performance advantages, this benefit comes at a price: they are harder to write. For this reason, R-core generally avoids creating them unless there is no other option.

R functions are often called ["first-class functions"](https://en.wikipedia.org/wiki/First-class_function).


>Unlike in many other languages, there is no special syntax for defining and naming a function: you simply create a function object (with `function`) and bind it to a name with `<-`

```{r}
f01 <- function(x) {
  sin(1 / x ^ 2)
}
```

If you don't bind a function to a name, you get an _anonymous function_ (equivalent to Python's lambda functions).

```{r}
integrate(function(x) sin(x) ^ 2, lower = 0, upper = 1)
purrr::map_int(mtcars, function(x) length(unique(x)))
```

You can also put functions inside a list:

```{r}
funs <- list(
  half = function(x) x / 2,
  double = function(x) x * 2
)

funs$double(33)
```

Note that we usually call a function by typing its arguments inside parentheses; e.g. `mean(1:10, na.rm = TRUE)`. But sometimes we want to use arguments that are already contained inside a data structure. We can use the `do.call()` function to "invoke" other functions.

For example:

```{r}
args <- list(1:10, na.rm = TRUE)
do.call(mean, args)
purrr::invoke(mean, args) ## purrr equivalent
```

>_Exercise_. This code makes a list of all functions in the base package.

```{r}
objs <- mget(ls("package:base", all = TRUE), inherits = TRUE)
funs <- Filter(is.function, objs)
```

>Use it to answer the following questions:

```{r, message=FALSE}
library(tibble)
library(purrr)

df <- tibble(
  function_name = names(funs),
  num_args = map(funs, formals) %>% map_int(length)
)

# *******************************************
# Which base function has the most arguments?
# *******************************************

df[df$num_args == max(df$num_args), ]

# *******************************************
# How many base functions have no arguments? 
# What’s special about those functions?
# *******************************************

nrow(df[df$num_args == 0, ])

# Note that we are overcounting the number of functions
# without arguments because formals() will return
# NULL for primitive functions.

# *******************************************
# How could you adapt the code to find all 
# primitive functions?
# *******************************************

funs <- Filter(is.primitive, objs)

```

### Composition

There are two ways to compose function calls in base R:

1. Nesting functions.

    >Nesting, `f(g(x))`, is concise, and well suited for short sequences. But longer sequences are hard to read because they are read inside out and right to left.

2. Saving intermediate results as variables.

    >Intermediate objects, `y <- f(x); g(y)`, requires you to name intermediate objects. This is a strength when objects are important, but a weakness when values are truly intermediate.

Additionally, the [__magrittr__](https://magrittr.tidyverse.org/) package provides a third option.

3. The pipe operator.

****

_Example. Calculating the standard deviation of a numeric vector._

```{r}
square <- function(x) x^2
deviation <- function(x) x - mean(x)
x <- runif(100)

# ****************************
# 1. Nesting calls
# ****************************

sqrt(mean(square(deviation(x))))

# ****************************
# 2. Saving intermediate results
# ****************************

out <- deviation(x)
out <- square(out)
out <- mean(out)
out <- sqrt(out)
out

# ****************************
# 3. %>% %>% %>% %>% %>% %>% %>% 
# ****************************

x %>% 
  deviation() %>% 
  square() %>% 
  mean() %>% 
  sqrt()
```

>The pipe allows you to focus on the high-level composition of functions rather than the low-level flow of data; the focus is on what’s being done (the _verbs_), rather than on what’s being modified (the _nouns_). This style is common in Haskell and F#, the main inspiration for magrittr, and is the default style in stack based programming languages like Forth and Factor.

>Piping, `x %>% f() %>% g()`, allows you to read code in straightforward left-to-right fashion and doesn’t require you to name intermediate objects. But you can only use it with linear sequences of transformations of a single object. It also requires an additional third party package and assumes that the reader understands piping.

### Lexical scoping

Scoping is the act of finding the _value_ associated with a _name_. Experienced R users find all of this very intuitive, but new users won't necessarily think the same way.

```{r}
x <- 10
g01 <- function() {
  x <- 20
  x
}

g01()
x
```

>R uses __lexical scoping__: it looks up the values of names based on how a function is defined, not how it is called. "Lexical" here is [...] a technical CS term that tells us that the scoping rules use a parse-time, rather than a run-time structure.

There are four main rules in R's lexical scoping:

1. __Name masking__. Names defined inside a function mask names defined outside a function. And if a name isn't defined inside a function, R looks one level up.

    ```{r}
    x <- 2
    
    g03 <- function() {
      y <- 1
      c(x, y)
    }
    
    g03()
    x <- 9
    g03()
    ```

    >The same rules apply if a function is defined inside another function. First, R looks inside the current function. Then, it looks where that function was defined (and so on, all the way up to the global environment). Finally, it looks in other loaded packages.

2. __Functions versus variables__. Name masking also applies when applied to functions; after all, they're just ordinary R objects. However, there is a subtle distinction. 

    >When you use a name in a function call, R ignores non-function objects when looking for that value.
    
    ```{r}
    a <- function(x) x + 100
    b <- function() {
      a <- 10
      a(a) ## R takes the "left a" from outside the function
    }      ## environment, and the "inside a" one from within.
    b()
    ```

3. __A fresh start__. Every time a function is called, a new environment is created to host its execution. In other words, is "invocation" is completely independent of each other.

4. __Dynamic lookup__. Lexical scoping determines _where_, but not _when_ to look for values. 

    >R looks for values when the function is run, not when the function is created. Together, these two properties tell us that the output of a function can differ depending on the objects outside the function’s environment.
    
    This means that
    
    >If you make a spelling mistake in your code, you won’t get an error message when you create the function. And depending on the variables defined in the global environment, you might not even get an error message when you run the function.
    
```{r}
# Use the following to find all unbound symbols (external 
# dependencies) within a function:
codetools::findGlobals(g03)
```

>R relies on lexical scoping to find __everything__, from the obvious, like `mean()`, to the less obvious, like `+` or even `{`. This gives R’s scoping rules a rather beautiful simplicity.

### Lazy evaluation

In R, function arguments are only evaluated _if_ accessed. This is also known as _lazy evaluation_.

```{r}
h01 <- function(x) 10
h01(asdASDFfasdfASDFawef) ## no error because asdASDFfasdfASDFawef is never used
```

Lazy evaluation is powered by a data structure called a __promise__ (or a [_thunk_](https://en.wikipedia.org/wiki/Thunk)). 

A promise has three components:

1. An _expression_ (e.g. `x + y`) which gives rise to the delayed computation.

2. An _environment_ where the expression should be evaluated (i.e. the environment where the function is called). 

3. A _value_, which is computed and cached the first time a promise is accessed when the expression is evaluated in the specified environment. _This ensures that the promise is evaluated at most once._

>You cannot manipulate promises with R code. Promises are like a quantum state: any attempt to inspect them with R code will force an immediate evaluation, making the promise disappear.

Note. An exception to this behavior is provided by the "quosure" object in the [__`rlang`__](https://rlang.r-lib.org/) package.

Lazy evaluation allows for default values to be defined in terms of other arguments, or even in terms of variables defined inside the function. 

```{r}
h04 <- function(x = 1, y = x * 2, z = a + b) {
  a <- 10; b <- 100 ## not recommended!!!
  c(x, y, z)
}

h04()
```

```{r}
ls()
```

>The evaluation environment is slightly different for default and user supplied arguments, as default arguments are evaluated inside the function. This means that seemingly identical calls can yield different results. It’s easiest to see this with an extreme example:

```{r}
h05 <- function(x = ls()) {
  a <- 1
  x
}

# ls() evaluated inside h05:
h05()
# ls() evaluated in global environment:
h05(x = ls())
```

The `missing()` function will help you determine if an argument's value comes from the user or from a default.

```{r}
h06 <- function(x = 10) list(missing(x), x)
str(h06())
str(h06(20))
```

This special function is behind `sample()`'s erratic behavior.

```{r}
formals(sample)
body(sample)
```

```{r}
sample(5)
sample(5, size = 2)
```

### `...` (dot-dot-dot)

Functions with `...` as an argument can take any number of additional arguments. You can also use `...` to pass those additional arguments to another function. In some programming languages, these are known as [_variadic functions_](https://en.wikipedia.org/wiki/Variadic_function) (i.e. they accept a variable number of arguments).

For example:

```{r}
i01 <- function(y, z) {
  list(y = y, z = z)
}

i02 <- function(x, ...) {
  i01(...)
}

str(i02(x = fdsaasdf, y = 2, z = 3))
```

Using `list(...)` inside a function will evaluate the dot-dot-dot arguments and store them in a list.

```{r}
i04 <- function(x, ...) list(...)
str(i04(a = 1:5, b = "arg", c = 9, 10))
```

Two primary uses of dot-dot-dot:

1. Passing additional arguments to a function inside a function. 

```{r}
# lapply() uses ... to pass na.rm to the mean() function
x <- list(c(1, 3, NA), c(4, NA, 6))
str(lapply(x, mean, na.rm = TRUE))
```

2. Generic functions (e.g. `print`, `summary`) need some way to allow methods to take arbitrary arguments; in other words, `...` allows individual methods to have different arguments.

There is one big downside to dot-dot-dot. 

>A misspelled argument will not raise an error. This makes it easy for typos to go unnoticed.

```{r}
## na_rm is a typo
sum(1, 2, NA, na_rm = TRUE)
sum(1, 2, na_rm = TRUE)
```

### Exiting

Most functions exit when they return a value (success) or when they throw an error (failure).

SOMETIMES EXIT HANDLER

>exit handlers, which allow you to run code when a function exits.

___Returns___

```{r}
j01 <- function() 10            ## implicit return
j01() 

j02 <- function() return(10)    ## explicit return()
j02()
```

You can prevent automatic printing by applying `invisible()` to the last value.

```{r}
j03 <- function() invisible(10)    ## implicit and invisible
j03()
```

> To verify that this value does indeed exist, you can explicitly print it or [wrap it in parentheses](https://yihui.name/en/2017/06/top-level-r-expressions/)

```{r}
print(j03())  # explicit printing
(j03())       # "ghost printing"
```

>Alternatively, you can use `withVisible()` to return the value and a visibility flag:

```{r}
withVisible(j03())
```

The most common function that returns invisibly is the assignment function `<-`.

```{r}
a <- 2
(a <- 2)
```

>In general, any function called primarily for a side effect (like `<-`, `print()`, or `plot()`) should return an invisible value (typically the value of the first argument).

___Errors___

If, for some reason, a function cannot complete its assigned task, it should throw an error with `stop()`, which immediately terminates the execution of the function.

```{r, error=TRUE}
j04 <- function() {
  stop("I'm an error")
  return(10)
}
j04()
```

An error should indicate that something has gone wrong, and force the user to deal with the problem.

Sometimes a function will need to make temporary changes to the global state, and we therefore need a painless way to ensure that these changes are undone regardless of how a function exits. To achieve this, we use `on.exit()` to set up an __exit handler__. _Any  exit handler is run independently of whether the function exits normally or with an error._

>Coupled with lazy evaluation, this creates a very useful pattern for running a block of code in an altered environment:

```{r}
with_dir <- function(dir, code) {
  old <- setwd(dir)  ## sets new wd, but saves old one in "old"
  on.exit(setwd(old), add = TRUE)  ## sets old wd

  force(code)
}

with_dir("~", getwd())
getwd()
with_dir("..", list.files())
```

>The use of `force()` isn’t strictly necessary here as simply referring to code will force its evaluation. However, using `force()` makes it very clear that we are deliberately forcing the execution.

__Note__. `force()` is rarely useful, but plays an important role when working with "function factories".

__Note__. `on.exit()` allows users to work with what Python users know as "context managers". As such, this function is important when setting up connections to databases.

### Function forms 

>While everything that happens in R is a result of a function call, not all calls look the same.

Four types of functions:

1. __Prefix__: functions whose name come before the arguments, like `f(a, b, c)`. 

2. __Infix__: functions whose name comes in between the arguments, like `x + y`. These are usually used for mathematical operators or user-defined functions that begin and end with `%`, like the pipe.

3. __Replacement__: functions that replace values by assignment, like `names(df) <- c("a", "b", "c")`. They look like prefix functions.

4. __Special__: functions like `[[`, `if`, and `for.` They don’t have a consistent structure.

All four forms can be rewritten in prefix form.

```{r}
1 + 2                             ## infix
`+`(1, 2)                         ## prefix

df <- data.frame(x = 1:10, y = 21:30, z = 31:40)
names(df) <- c("x", "y", "z")     ## replacement
`names<-`(df, c("x", "y", "z"))   ## prefix

for (i in 1:5) cat(i)             ## special
`for`(i, 1:5, cat(i))             ## prefix
```

Pretty much every operation in R can be _called_ as a prefix function. This means that we can override the behavior of regular functions.

```{r}
## This example introduces a bug in the "(" function 20% of the time.
`(` <- function(x) {
  if (is.numeric(1) & runif(1) < 0.2) {
    x + 1
  } else {
    x
  }
}

replicate(30, (1 + 1))

rm("(")
```

****

___More details___

<blockquote>
The __prefix form__ is the most common form in R code, and indeed in the majority of programming languages. Prefix calls in R are a little special because you can specify arguments in three ways:

- By _position_, like `help(mean)`.
- Using _partial matching_, like `help(top = mean)`.
- By _name_, like `help(topic = mean)`.

As illustrated by the following chunk, arguments are matched by exact name, then with unique prefixes, and finally by position.
</blockquote>

```{r, error=TRUE}
k01 <- function(abcdef, bcde1, bcde2) {
  list(a = abcdef, b1 = bcde1, b2 = bcde2)
}

str(k01(1, 2, 3))             ## by position
str(k01(1, 2, abcdef = 3))    ## by name and position
str(k01(1, 2, a = 3))         ## by partial matching and position

# This won't work when partial matching is ambiguous
k01(1, 2, b = 3)
```

>In general, use positional matching only for the first one or two arguments; they will be the most commonly used, and most readers will know what they are. Avoid using positional matching for less commonly used arguments, and never use partial matching. Unfortunately you can’t disable partial matching, but you can turn it into a warning with the `warnPartialMatchArgs` option:

```{r}
options(warnPartialMatchArgs = TRUE)
invisible(k01(1, 2, a = 3))
```

```{r, echo=FALSE}
options(warnPartialMatchArgs = FALSE)
```


>__Infix functions__ get their name from the fact the function name comes inbetween its arguments, and hence have two arguments. R comes with a number of built-in infix operators: `:`, `::`, `:::`, `$`, `@`, `^`, `*`, `/`, `+`, `-`, `>`, `>=`, `<`, `<=`, `==`, `!=`, `!`, `&`, `&&`, `|`, `||`, `~`, `<-`, and `<<-`. You can also create your own infix functions that start and end with `%`. Base R uses this pattern to define `%%`, `%*%`, `%/%`, `%in%`, `%o%`, and `%x%`.

_Example. Defining an infix function that concatenates strings._

```{r}
`%+%` <- function(a, b) paste(a, b)
"new" %+% "string"
```

>R's default precedence rules mean that infix operators are composed left to right:

```{r}
`%-%` <- function(a, b) paste0("(", a, " %-% ", b, ")")
"a" %-% "b" %-% "c"
```

>There are two special infix functions that can be called with a single argument: `+` and `-`.

```{r}
-1; +10
```

>__Replacement functions__ act like they modify their arguments in place, and have the special name `xxx<-`. They must have arguments named `x` and `value`, and must return the modified object. For example, the following function modifies the second element of a vector:

```{r}
`second<-` <- function(x, value) { 
  x[2] <- value
  return(x) 
}

x <- 1:5
second(x) <- 99L  ## function call is on the left side of <-
x
```

>If your replacement function needs additional arguments, place them between `x` and `value`, and call the replacement function with additional arguments on the left:

```{r}
`modify<-` <- function(x, position, value) {
  x[position] <- value
  x
}
modify(x, 1) <- 10
```

Note that, due to R's copy-on-modify semantics, these functions don't actually modify their arguments in place: they create a modified copy.

```{r}
obj_addr(x)
modify(x, 1) <- 5L
obj_addr(x)
```

Finally, we have __special functions__, that can also be rewritten in prefix form.

Parentheses: 

- `(x)` becomes ``` `(`(x) ```
- `{x}` becomes ``` `{`(x) ```

Subsetting operators:

- `x[i]` becomes ``` `[`(x, i) ```

- `x[[i]]` becomes ``` `[[`(x, i) ```

Control flow:

- `if (cond) true` becomes ``` `if`(cond, true) ```

- `if (cond) true else false` becomes ``` `if`(cond, true, false) ```

- `for(var in seq) action` becomes ``` `for`(var, seq, action) ```

- `while(cond) action` becomes ``` `while`(cond, action) ```

- `repeat expr` becomes  ``` `repeat`(expr) ```

- `next` becomes ``` `next`() ```

- `break` becomes ``` `break`() ```

>Finally, the most complex is the `function` function:

- `function(arg1, arg2) {body}` becomes ``` `function`(alist(arg1, arg2), body, env) ```

## Environments

>The environment is the __data structure__ that powers scoping.

R environments are the powerhouses behind many important features such as _scoping_, _namespaces_, and _R6 classes_.

```{r, message=FALSE}
library(rlang)
```

>This chapter will use [__`rlang`__](https://rlang.r-lib.org/) functions for working with environments.

>The `env_` functions in rlang are designed to work with the pipe: all take an environment as the first argument, and many also return an environment. 

Here we learn about __binding__ environments, and _special environments_: __package__, __namespace__, __function__, __execution__, and __caller__ environments. We also learn how to work with _environments as data structures_.

### Basics

To create an environment, we use `rlang::env()`. 

>The job of an environment is to associate, or __bind__, a set of names to a set of values. You can think of an environment as a bag of names, with no implied order (i.e. it doesn’t make sense to ask which is the first element in an environment). For that reason, we’ll draw the environment as so:

```{r}
e1 <- env(
  a = FALSE,
  b = "a",
  c = 2.3,
  d = 1:3,
)
```


```{r, echo=FALSE, out.width="300px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/f5dbd02f5235283e78decdd4f18692b40f1ddf42/c5683/diagrams/environments/bindings.png"
)
```

In other words, environments in R are similar to hashmaps (or "dictionaries" in Python). Environments have __reference semantics__.

>...unlike most R objects, when you modify them, you modify them in place, and don’t create a copy. One important implication is that environments can contain themselves.

```{r}
e1$d <- e1
```

```{r, echo=FALSE, out.width="300px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/0d41862821d3226c38b73f78a530117349b7344a/abb88/diagrams/environments/loop.png"
)
```

If you try to print an environment, you won't see any useful information (just the memory address). That's why we use `rlang::env_print()`.

```{r}
print(e1)
env_print(e1)
```

And we use `rlang::env_names()` to get a character vector that gives the current bindings.

```{r}
env_names(e1)  ## equivalent to base::names(e1) as of R 3.2.0
```

>The __current environment__, or `current_env()` is the environment in which code is currently executing. When you’re experimenting interactively, that’s usually the global environment, or `global_env()`. The global environment is sometimes called your "workspace", as it’s where all interactive (i.e. outside of a function) computation takes place.

>To compare environments, you need to use `identical()` and not `==`. This is because `==` is a vectorised operator, and environments are _not_ vectors.

```{r, error=TRUE}
current_env()
global_env() == current_env()
identical(global_env(), current_env())
```

>Every environment has a __parent__, another environment. In diagrams, the parent is shown as a small pale blue circle and arrow that points to another environment. The parent is what’s used to implement lexical scoping: if a name is not found in an environment, then R will look in its parent (and so on). You can set the parent environment by supplying an unnamed argument to `env()`. If you don’t supply it, it defaults to the current environment. In the code below, `e2a` is the parent of `e2b`.

```{r}
e2a <- env(d = 4, e = 5)
e2b <- env(e2a, a = 1, b = 2, c = 3)
```

```{r, echo=FALSE, out.width="350px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/336e61bf494a6424484b8b2685a440a7db1566bf/59bce/diagrams/environments/parents.png"
)
```

In these diagrams, every pale blue dot indicates the existence of a parent environment.

>You can find the parent of an environment with `env_parent()`:

```{r}
env_parent(e2a)
env_parent(e2b)
```

Only _the empty environment_ has no parents.

```{r, error=TRUE}
empty_env()
env_parent(empty_env())
```

You can see all ancestors with the `env_parents()` function:

```{r}
env_parents(e2b)

e2c <- env(empty_env(), d = 4, e = 5)
e2d <- env(e2c, a = 1, b = 2, c = 3)

env_parents(e2d)
```

`env_parents()` stops when it gets to the global environment; the global environment's ancestors include every attached package, so this provides the most useful information. But we can always override this default behavior by adding an extra argument to the function call. Note that the ancestors of every environment will eventually lead back to the empty environment.

```{r}
env_parents(e2b, last = empty_env())
```

That's right. Every package attached by `library()` or `require()` becomes one of the parents of the global environment. The last package you attach becomes the global environment's immediate parent. 

>If you follow all the parents back, you see the order in which every package has been attached. This is known as the __search path__ because all objects in these environments can be found from the top-level interactive workspace. You can see the names of these environments with `base::search()`, or the environments themselves with `rlang::search_envs()`:

```{r}
base::search()
rlang::search_envs()
```

R packages are one example of __special environments__.

The last two environments on the search path will always be the same: `Autoloads` and `package:base`

>The `Autoloads` environment uses delayed bindings to save memory by only loading package objects (like big datasets) when needed.

>The base environment [...] is special because it has to be able to bootstrap the loading of all other packages. You can access it directly with `base_env()`.

```{r}
base_env() %>% env_names() %>% sample(size = 10)
```

Ancestors of environments provide the basis for understanding the "super assignment" operator `<<-`.

Unlike `<-`, the `<<-` operator never creates a variable in the current environment. Instead, it modifies an existing variable found in a parent environment.

```{r}
x <- 0
f <- function() x <<- 1
f()
x
```

>If `<<-` doesn’t find an existing variable, it will create one in the global environment.

___Getting and setting___

>You can get and set elements of an environment with `$` and `[[` in the same way as a list:

```{r}
e3 <- env(x = 1, y = 2)
e3[["x"]]
e3$z <- 3
e3$z <- 4
e3[["z"]]
```

>But you can’t use `[[` with numeric indices, and you can’t use `[`.

Furthermore, if the binding doesn't exist, `$` and `[[` will return a `NULL` value.

```{r}
e3$w
```

To get an error (or a default value different from `NULL`) we use `env_get()`.

```{r, error=TRUE}
env_get(env = e3, nm = "w")
env_get(e3, "w", default = NA)
```

We can see whether an environment has a binding or not with `env_has()`.

```{r}
env_has(e3, "w")
```

A big difference with respect to lists is that setting an element to `NULL` will not remove it. If we want to remove it, we have to use `env_unbind()`.

```{r}
e3$a <- NULL
env_print(e3)
```


****

___Two other ways to add bindings to an environment___

- `env_poke()` takes a `name` (as string) and a `value`. The word "poke" is meant to convey that this function "modifies in place" (i.e. it doesn't copy-on-modify).

    ```{r}
    env_poke(e3, "w", 1:5)
    e3$w
    ```

- `env_bind()` allows you to bind multiple values
    
    ```{r}
    env_bind(e3, a = 10, b = 20)
    env_names(e3)
    ```
    
Note that `env_bind()` has two more variants: 

>`env_bind_lazy() `creates delayed bindings, which are evaluated the first time they are accessed. Behind the scenes, delayed bindings create promises, so behave in the same way as function arguments.

```{r}
env_bind_lazy(current_env(), b = {Sys.sleep(2); 1})
system.time(b)
system.time(b)
```

The main purspose of delayed bindings is to provide R users with datasets that behave like they are loaded in memory even though they're not.

>`env_bind_active()` creates active bindings which are re-computed every time they’re accessed:

```{r}
env_bind_active(current_env(), z1 = function() runif(5))
str(z1)
str(z1)
```

The main purspose of active bindings becomes clear when using the R6 OOP system.

### Other special environments

___The function environment___

> A function _binds_ the current environment when it is created. This is called the _function environment_, and is used for lexical scoping. Across computer languages, functions that capture (or enclose) their environments are called __closures__, which is why this term is often used interchangeably with function in R's documentation.

Note that the common error `object of type 'closure' is not subsettable` means that you're probably trying to subset a function instead of a vector.

```{r, error=TRUE}
mean[[1]]
```

>You can get the function environment with `rlang::fn_env()`:

```{r}
y <- 1
f <- function(x) x + y
fn_env(f)
fn_env(fn_env)
```

In the diagrams drawn by Hadley Wickham, functions are represented as rectangles with a rounded end that binds an environment.

```{r, echo=FALSE, out.width="200px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/cd8208b418ecbaf6ace1b6453b93fdf628173e01/68d59/diagrams/environments/binding.png"
)
```

>In this case, `f()` binds the environment that binds the name `f` to the function. But that’s not always the case: in the following example `g` is bound in a new environment e, but `g()` binds the global environment. The distinction between binding and being bound by is subtle but important; the difference is how we find `g` versus how `g` finds its variables.

```{r}
e <- env()
e$g <- function(x) x + y
fn_env(e$g)
```

```{r, echo=FALSE, out.width="200px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/cd32bb2bc59dcfa579b0415ebac271f24c6a85fd/cde86/diagrams/environments/binding-2.png"
)
```

___Namespaces___

We have established that attaching a new package with `library()` will change the parent environment of the global environment.

>This seems worrying: doesn’t that mean that the package will find different functions if packages are loaded in a different order? The goal of __namespaces__ is to make sure that this does not happen, and that every package works the same way regardless of what packages are attached by the user.

For example, suppose that we define a new function named `var`. This overwrites the binding to the `stats::var()` function. Namespaces are what keeps this from messing up the `sd()` function, which contains `var()`.

```{r}
var <- function() "new function"
sd
sd(rnorm(100))
```

R avoids this potential nightmare by carefully distinguishing between _binding_ and _function_ environments.

_Every function in a package is associated with a pair of environments:_ the __package environment__ and the __namespace environment__.

>The package environment is the external interface to the package. It’s how you, the R user, find a function in an attached package or with `::`. Its parent is determined by search path, i.e. the order in which packages have been attached.

>The namespace environment is the internal interface to the package. The package environment controls how we find the function; _the namespace controls how the function finds its variables_.
>
>Every binding in the package environment is also found in the namespace environment; this ensures every function can use every other function in the package.

Every namespace environment has the same set of of ancestors, in accordance with the following figure:

```{r, echo=FALSE, out.width="400px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/3184a9827ac2c26c60f65680157241819f55e754/542c2/diagrams/environments/namespace-env.png"
)
```

>Each namespace has an __imports__ environment that contains bindings to all the functions used by the package. The imports environment is controlled by the package developer with the `NAMESPACE` file.

>Explicitly importing every base function would be tiresome, so the parent of the imports environment is the __base namespace.__ The base namespace contains the same bindings as the base environment, but it has a different parent: [the global environment].

Now we can understand how `sd()` keeps working even after we change the binding for `var()`. When we use `stats::sd()`, R searches for the value of `var()`'s binding in `namespace:stats`.

```{r, echo=FALSE, out.width="400px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/fbbfd3b49bdbd3ca1913043233d48454ec27f14e/ae75a/diagrams/environments/namespace.png"
)
```

>There’s no direct link between the package and namespace environments; the link is defined by the function environments.

___The execution environment___

Recall _the fresh start principle_, according to which every time a function is called, a new environment is created to host its execution. This is _the execution environment_, whose parent is the _function environment_.

Take a look at the following code chunk and ensuing diagram:

```{r}
h <- function(x) { # 1. Function called with x = x
  a <- 2           # 2. "a" is bound to value "2"
  x + a            # 3. Function returns a value
}
y <- h(1) # The value "3" is returned, execution environment goes away.
```

```{r, echo=FALSE, out.width="350px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/862b3606a4a218cc98739b224521b649eeac6082/5d3e9/diagrams/environments/execution.png"
)
```

If, for some reason, we don't want the function environment to dissapear, we can always explictly return it.


```{r}
h2 <- function(x) {
  a <- x * 2
  rlang::current_env()
}

e <- h2(2)
e
e$x
e$a
```

_A brief introduction to function factories_

>Another way to capture it is to return an object with a binding to that environment, like a function. The following example illustrates that idea with a __function factory__, `plus()`. We use that factory to create a function called `plus_one()`.

```{r}
plus <- function(x) {
  function(y) x + y
}

plus_one <- plus(1)
plus_one
rlang::fn_env(plus)
rlang::fn_env(plus_one)
```

```{r, echo=FALSE, out.width="200px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/853b74c3293fae253c978b73c55f3d0531d746c5/6ffd5/diagrams/environments/closure.png"
)
```

And when we call `plus_one()`, its execution environment captures the execution environment of `plus()` as its parent environment:

```{r}
plus_one(2)
```

```{r, echo=FALSE, out.width="200px"}
knitr::include_graphics(
"https://d33wubrfki0l68.cloudfront.net/66676485e6a22c807c19b0c54c8fda6bd1292531/3526e/diagrams/environments/closure-call.png"
)
```


### Call stacks
 
The __caller environment__ is the environment from which a function is called; this environment might vary depending on _how_ the function is called. We access the caller environment with `rlang::caller_env()`.

>To fully understand the caller environment we need to discuss two related concepts: the __call stack__, which is made up of __frames__. Executing a function creates two types of context. You’ve learned about one already: the execution environment is a child of the function environment, which is determined by where the function was created. There’s another type of context created by where the function was called: this is called the call stack.

___Call stacks___

The most common way of seeing call stacks in R is by looking at the `traceback()` after an error has occurred. Here, we'll instead use `lobstr::cst()` to print out the __c__all __s__tack __t__ree.

```{r}
f <- function(x) {
  g(x = 2)
}
g <- function(x) {
  h(x = 3)
}
h <- function(x) {
  lobstr::cst()
}

f(x = 1)
```

That is, `cst()` was called from `h()`, which was called from `g()`, which was called from `f()`. Even though we get a glimpse at the tree-like structure of call stacks, this one in particular is very simple: everything happens on a single branch. There are more complicated structures that arise from __lazy evaluation__. 

For example:

```{r}
a <- function(x) b(x)
b <- function(x) c(x)
c <- function(x) x

a(f())
```

___Frames___

>Each element of the call stack is a __frame__, also known as an _evaluation context_. The frame is an extremely important internal data structure, and R code can only access a small part of the data structure because tampering with it will break R. A frame has three key components:

1. An _expression_ (usually labelled with `expr`) giving the function call. This is what `traceback()` prints out.

2. An _environment_, which is typically the execution environment of a function. There are two main exceptions: the environment of the global frame is the global environment, and calling `eval()` also generates frames, where the environment can be anything.

3. A _parent_, the previous call in the call stack.

>The frame also holds exit handlers created with `on.exit()`, restarts and handlers for the condition system, and which context to `return()` to when a function completes. These are important internal details that are not accessible with R code.

>Looking up variables in the calling stack rather than in the enclosing environment is called __dynamic scoping__. Few languages implement dynamic scoping. This is because dynamic scoping makes it much harder to reason about how a function operates: not only do you need to know how it was defined, you also need to know the context in which it was called.

### Computing with environments

>If you want to operate on every ancestor of an environment, it’s often convenient to write a recursive function. This section shows you how, applying your new knowledge of environments to write a function that given a name, finds the environment `where()` that name is defined, using R’s regular scoping rules [_lexical scoping_].

```{r}
where <- function(name, env = caller_env()) {
  if (identical(env, empty_env())) {
    # Base case
    stop("Can't find ", name, call. = FALSE)
  } else if (env_has(env, name)) {
    # Success case
    env
  } else {
    # Recursive case
    where(name, env_parent(env))
  }
}

where("mean")
```

Note the three cases:

1. _Base case_: we reach the empty environment without finding a binding, so we throw an error with `stop()`.

2. _Success case_: the name exists in the environment we call.

3. _Recursive case_: the name isn't found in the environment, so we go one level up (i.e. we do the same thing all over again with the environment's parent).

Removing the specifics for `where()`, we get a fairly straightforward template for recursing over environments.

```{r, eval=FALSE}
f <- function(..., env = caller_env()) {
  if (identical(env, empty_env())) {
    # base case
  } else if (success) {
    # success case
  } else {
    # recursive case
    f(..., env = env_parent(env))
  }
}
```

### Exercises

> Modify `where()` to return all environments that contain a binding for name. Carefully think through what type of object the function will need to return.

```{r}
where2 <- function(name, env = caller_env(), output = list()) {
  if (identical(env, empty_env())) {
    # Base case
    output
  } else {
    # Recursive case
    if (env_has(env, name)) {
      output <- append(output, env)
    }
    where2(name, env_parent(env), output)
  }
}

## Looping instead of recursion
where3 <- function(name, env = caller_env()) {
  output <- list()
  for (e in c(env, env_parents(env))) {
    if (env_has(e, name)) {
      output <- append(output, e)
    }
  }
  return(output)
}
```

> Write a function called `fget()` that finds only function objects. It should have two arguments, name and env, and should obey the regular scoping rules for functions: if there’s an object with a matching name that’s not a function, look in the parent. For an added challenge, also add an inherits argument which controls whether the function recurses up the parents or only looks in one environment.

```{r}
fget <- function(name, env = caller_env(), inherits = TRUE) {

  if (env_has(env, name) & is.function(env[[name]])) {
    return(env[[name]])
  } 
  
  if (identical(env, empty_env()) | inherits == FALSE) {
    stop("Can't find function \"", name, "\"", call. = FALSE)
  } 
  
  # Recursive case
  fget(name, env_parent(env))

}
```

>_Exercise._ Write a function that lists all the variables defined in the environment in which it was called. It should return the same results as `ls()`.

```{r, eval=FALSE}
ls2 <- function(env = caller_env()) { env_names(env) }
```

>List three ways in which an environment differs from a list

1. The elements contained in lists can be extracted with numerical indices using `[[`. The elements contained environments cannot be extracted with numerical indices because they are _unordered_.
2. Environments have parents.
3. Environments have reference semantics, which means that they don't copy-on-modify.

## Conditions

The __condition__ system allows _users_ and _creators_ of functions to communicate with each other.

>The function author __signals__ conditions with functions like `stop()` (for errors), `warning()` (for warnings), and `message()` (for messages), then the function user can __handle__ them with functions like `tryCatch()` and `withCallingHandlers()`.

__Three signals:__

1. _Errors_ are signalled or thrown with `stop()`. We will use `rlang::abort()`, which does the same thing as `stop()` but also has the ability to add additional metadata to the condition object. On the other hand, `stop()` pastes together multiple inputs, while `abort()` does not (use `paste0()` or `glue::glue()` to compose long error messages).

    ```{r, error=TRUE}
    h <- function() abort("This is an error!")
    h()
    ```
    
    Good error messages tell you what went wrong and point you in the right direction. See [here](https://style.tidyverse.org/error-messages.html) for a few good general principles to follow when writing error messages.

2. _Warnings_ signal that something has gone wrong, but the function has been able to recover and continue. Keep in mind that some R users tend to overuse warnings, and that we would be better off if they were treated as errors.

    We can easily debug warnings by setting `options(warn = 2)` which turns them into errors. We can then use tools like `traceback()` to find the source of the error. Finally, restore the default behaviour with `options(warn = 0)`.

    The rlang equivalent of `warning()` is `rlang::warn()`.
    
3. _Messages_ provide the user with relevant information.

    >Good messages are a balancing act: you want to provide just enough information so the user knows what's going on, but not so much that they're overwhelmed.

### Handling conditions

The easiest way to handle conditions in R is simply to __ignore__ them.

- Ignore errors with `try()`

- Ignore warnings with `suppressWarnings()`

- Ignore messages with `suppressMessages()`

```{r}
## Example 1
f <- function() {
  try(log("a")) # This error doesn't stop 10 from printing
  10
}

f()

## Example 2
suppressWarnings({
  warning("This warning never gets printed!")
  10
})

```

These functions suppress _everything._ If we instead want to suppress only a particular subset of well-defined conditions, we use `tryCatch()` and `withCallingHandlers()`. Collectively, these functions are known as __condition handlers__.

>Every condition has default behaviour: errors stop execution and return to the top level, warnings are captured and displayed in aggregate, and messages are immediately displayed. Condition handlers allow us to temporarily override or supplement the default behaviour.

_Handlers are functions that take the signalled condition as their only argument._

> `tryCatch()` defines __exiting handlers__; after the condition is handled, control returns to the context where `tryCatch()` was called. This makes `tryCatch()` most suitable for working with errors and interrupts, as these have to exit anyway.

> `withCallingHandlers()` defines __calling handlers__; after the condition is captured control returns to the context where the condition was signalled. This makes it most suitable for working with non-error conditions.

Both functions work with __condition objects__ (i.e. the objects that are created behind the scenes whenever a condition is signalled). These objects become explicit inside the handlers. 

Built-in conditions (as opposed to _custom_ conditions) are lists with two elements:

- `message`, a character vector containing the text to displayed to the user. To extract the message, use `conditionMessage()`.

- `call`, the call which triggered the condition.

The easiest way to see a condition object is to catch one from a signalled condition using `rlang::catch_cnd()`.

```{r}
cnd <- catch_cnd(stop("An error"))
str(cnd)
cnd <- catch_cnd(stop("An error", call. = FALSE))  ## call might be NULL in many situations
str(cnd)
```

Note that conditions also have a class attribute, which makes them S3 objects. 

```{r}
class(cnd)
```

### `tryCatch()`

Recall that the handler function takes the signalled condition as its only argumenwhich we conventionally name `cnd` or `cond`. Knowing this, the basic form of exit handler is as follows:

```{r, eval=FALSE}
tryCatch(
  error = function(cnd) {
    # code to run when error is thrown
  },
  code_to_run_while_handlers_are_active
)
```

For example:

```{r}
tryCatch(
  error = function(cnd) { "There" }, 
  {
    stop("This code is never run!")
    message("Here")
  }
)

f <- function(x) {
  tryCatch(
    error = function(cnd) { NA },
    log(x)
  )
}

f("asdf")
```

>The protected code is evaluated in the environment of `tryCatch()`, but the handler code is not, because the handlers are functions. This is important to remember if you’re trying to modify objects in the parent environment.
 
`tryCatch()` can have one other argument: `finally`. It specifies a block of code (not a function) to run regardless of whether the initial expression succeeds or fails. We use this for things like for clean up, deleting files, or closing connections (Note: This is how `on.exit()` is implemented).

### `withCallingHandlers()`

Just as with `tryCatch()`, the basic form of a calling hanlder is as follows:

```{r, eval=FALSE}
withCallingHandlers(
  warning = function(cnd) {
    # code to run when warning is signalled
  },
  message = function(cnd) {
    # code to run when message is signalled
  },
  code_to_run_while_handlers_are_active
)
```

Unlike `tryCatch()`, however, code execution continues after the handler returns a message.

```{r}
tryCatch(
  message = function(cnd) cat("Caught a message!\n"), 
  {
    message("Someone there?")
    message("Why, yes!")
  }
)

withCallingHandlers(
  message = function(cnd) cat("Caught a message!\n"), 
  {
    message("Someone there?")
    message("Why, yes!")
  }
)

```

### Custom conditions

Built-in conditions only have two elements: `message` and `call`. Custom conditions can contain additional metadata. `rlang::abort()` makes doing this very easy as you can supply a custom `.subclass` and additional metadata. 

For example:

```{r}
output <- catch_cnd(
  abort(
    "error_not_found",
    message = "Path `blah.csv` not found", 
    path = "blah.csv"
    )
  )

output
```

